{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключаем нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy.stats import norm as norm_d\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "from scipy.optimize import minimize\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.linalg import svdvals\n",
    "import scipy\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from functions import *\n",
    "from algorithms import *\n",
    "from tests import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства продублируем здесь задачу, которую мы решаем\n",
    "$$\n",
    "F(x) = f(x) + R(x) = \\frac{1}{m}\\sum\\limits_{i=1}^m\\underbrace{\\left(\\log\\left(1 + \\exp\\left(-y_i\\cdot (Ax)_i\\right)\\right) + \\frac{l_2}{2}\\|x\\|_2^2\\right)}_{f_i(x)} + \\underbrace{l_1\\|x\\|_1}_{R(x)} \\to \\min\\limits_{x\\in\\mathbb{R}^n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединим подготовку данных в одну функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset):\n",
    "    filename = \"datasets/\" + dataset + \".txt\"\n",
    "\n",
    "    data = load_svmlight_file(filename)\n",
    "    A, y = data[0], data[1]\n",
    "    m, n = A.shape\n",
    "    \n",
    "    if (2 in y) & (1 in y):\n",
    "        y = 2 * y - 3\n",
    "    if (2 in y) & (4 in y):\n",
    "        y = y - 3\n",
    "    assert((-1 in y) & (1 in y))\n",
    "    \n",
    "    sparsity_A = A.count_nonzero() / (m * n)\n",
    "    return A, y, m, n, sparsity_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L(dataset, A):\n",
    "    filename = \"dump/\"+dataset+\"_L.txt\"\n",
    "    file_path = Path(filename)\n",
    "    if file_path.is_file():\n",
    "        with open(filename, 'rb') as file:\n",
    "            L, average_L, worst_L = pickle.load(file)\n",
    "    else:\n",
    "        sigmas = svds(A, return_singular_vectors=False)\n",
    "        m = A.shape[0]\n",
    "        L = sigmas.max()**2 / (4*m)\n",
    "        \n",
    "        worst_L = 0\n",
    "        average_L = 0\n",
    "        denseA = A.toarray()\n",
    "        for i in range(m):\n",
    "            L_temp = (norm(denseA[i])**2)*1.0 / 4\n",
    "            average_L += L_temp / m\n",
    "            if L_temp > worst_L:\n",
    "                worst_L = L_temp\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump([L, average_L, worst_L],file)\n",
    "    return L, average_L, worst_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Разреженность матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрите датасеты $\\texttt{a9a}$, $\\texttt{gisette}$, $\\texttt{australian}$ и ещё любых 2 датасета на ваш вкус из LIBSVM https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html. Для каждого выбранного датасета проанализируйте какой тип матрицы лучше использовать -- $\\texttt{csr_matrix}$ или $\\texttt{numpy.ndarray}$ -- чтобы вычислять для данного датасета \n",
    "\n",
    "1) полный градиент и\n",
    "\n",
    "2) стох. градиент (рассмотреть батчи размера 1, 10, 100).\n",
    "\n",
    "Как видно из формулы для подсчёта градиента \n",
    "$$\n",
    "\\nabla f(x) = -\\frac{1}{m}\\cdot\\frac{A^\\top y}{1+\\exp(y\\odot Ax)}  + l_2 x,\n",
    "$$\n",
    "и стох. градиента по батчу $S = \\{i_1,i_2,\\ldots,i_k\\}$\n",
    "$$\n",
    "\\frac{1}{k}\\sum\\limits_{j=1}^k \\nabla f_{i_j}(x) = -\\frac{1}{k}\\cdot\\frac{A_S^\\top y_S}{1+\\exp(y_S\\odot A_Sx)}  + l_2 x,\n",
    "$$\n",
    "необходимо выполнить умножение $A^\\top$ (или $A_S^\\top$) на вектор и умножение $A$ (или $A_S$) на вектор, чтобы посчитать градиент (стох. градиент). Поэтому анализировать предлагается следующим способом: генерируется 5 случайных векторов размерности $n$, а затем в цикле много раз вычисляются градиенты (стох. градиенты) в указанных точках. Количество подсчётов градиентов выбирайте исходя из того, чтобы все умножения при одном из типов хранения матрицы $A$ занимали от 10 до 40 секунд. Для подсчёта стох. градиентов заранее насэмплируйте при помощи функции $\\texttt{randint}$ большую выборку элементов от $0$ до $m-1$ (например, выборку размера $10^7$ элементов), а затем вырезайте из неё подряд идущие непересекающиеся куски длиной $r$, где $r$ -- размер батча. Для удобства считайте, что $l_2 = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число функций в сумме:  32561 , размерность задачи:  123\n",
      "Константа гладкости всей функции:  1.5719196992226612\n",
      "Средняя константа гладкости     :  3.467276803535652\n",
      "Худшая константа гладкости      :  3.5\n",
      "Доля ненулевых элементов:  0.11275696922074716\n",
      "CPU times: user 229 ms, sys: 4.78 ms, total: 234 ms\n",
      "Wall time: 224 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = \"a9a\"\n",
    "A, y, m, n, sparsity_A = prepare_data(dataset)\n",
    "print(\"Число функций в сумме: \", m, \", размерность задачи: \", n)\n",
    "L, average_L, worst_L = compute_L(dataset, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
    "print(\"Константа гладкости всей функции: \", L)\n",
    "print(\"Средняя константа гладкости     : \", average_L)\n",
    "print(\"Худшая константа гладкости      : \", worst_L)\n",
    "print(\"Доля ненулевых элементов: \", sparsity_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию матрица $A$ хранится в формате $\\texttt{csr_matrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "denseA = A.toarray()\n",
    "print(type(A))\n",
    "print(type(denseA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Насэмплируем индексов для батчей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.4 ms, sys: 90.9 ms, total: 152 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_indices = randint.rvs(low=0, high=m, size=10000000, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример того, как выглядят тесты для полноградиентного случая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 180 µs, sys: 101 µs, total: 281 µs\n",
      "Wall time: 230 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = norm_d.rvs(size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_tests = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.85 s, sys: 0 ns, total: 7.85 s\n",
      "Wall time: 7.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    x = norm_d.rvs(size=n)\n",
    "    for i in range(num_of_tests):\n",
    "        logreg_grad(x, [A, y, 0, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 53.3 s, total: 2min 52s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    x = norm_d.rvs(size=n)\n",
    "    for i in range(num_of_tests):\n",
    "        logreg_grad(x, [denseA, y, 0, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример тестов для случая стох. градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_of_tests = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 0 ns, total: 11 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    x = norm_d.rvs(size=n)\n",
    "    for i in range(num_of_tests):\n",
    "        batch_ind = batch_indices[i*batch_size:(i+1)*batch_size]\n",
    "        logreg_grad(x, [A[batch_ind], y[batch_ind], 0, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 661 ms, sys: 8.57 ms, total: 670 ms\n",
      "Wall time: 662 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for j in range(5):\n",
    "    x = norm_d.rvs(size=n)\n",
    "    for i in range(num_of_tests):\n",
    "        batch_ind = batch_indices[i*batch_size:(i+1)*batch_size]\n",
    "        logreg_grad(x, [denseA[batch_ind], y[batch_ind], 0, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_sparse(A, y, x0, batch_indices, batch_size=None, flag=True):\n",
    "    for j in range(5):\n",
    "        x = norm_d.rvs(size=n)\n",
    "        for i in range(num_of_tests):\n",
    "            if batch_size:\n",
    "                idx = batch_indices[i*batch_size:(i+1)*batch_size]\n",
    "                logreg_grad(x, [A[idx], y[idx], x0, flag])\n",
    "            else:\n",
    "                logreg_grad(x, [A, y, x0, flag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_log_reg():\n",
    "    \n",
    "    df = pd.DataFrame(columns = [\n",
    "        'Dataset','M','N','L', 'Worst_L',\n",
    "        'Sparse GD Time','Dense GD Time',\n",
    "        'Sparse SGD Time (batch 1)','Dense SGD Time (batch 1)',\n",
    "        'Sparse SGD Time (batch 10)', 'Dense SGD Time (batch 10)',\n",
    "        'Sparse SGD Time (batch 100)','Dense SGD Time (batch 100)'])\n",
    "    \n",
    "    for dataset_name in ['a9a', 'a5a', 'australian', 'diabetes', 'heart']:\n",
    "        # load data\n",
    "        num_of_tests = 100\n",
    "        A, y, m, n, sparsity_A = prepare_data(dataset_name)\n",
    "        L, average_L, worst_L = compute_L(dataset_name, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
    "        # get dense numpy array\n",
    "        denseA = A.toarray()\n",
    "        # get indices for stochastic descent\n",
    "        batch_indices = randint.rvs(low=0, high=m, size=10000000, random_state=42)\n",
    "\n",
    "        ### test gradient descent\n",
    "        # sparse matrix case\n",
    "        t0 = time.time() \n",
    "        for j in range(5):\n",
    "            x = norm_d.rvs(size=n)\n",
    "            for i in range(num_of_tests):\n",
    "                logreg_grad(x, [A, y, 0, True])\n",
    "        t1 = time.time()\n",
    "        sparse_gd_t = t1 - t0\n",
    "\n",
    "        # dense matrix case\n",
    "        t0 = time.time()    \n",
    "        for j in range(5):\n",
    "            x = norm_d.rvs(size=n)\n",
    "            for i in range(num_of_tests):\n",
    "                logreg_grad(x, [denseA, y, 0, False])\n",
    "        t1 = time.time()  \n",
    "        dense_gd_t = t1 -t0\n",
    "\n",
    "        ### test stochastic gradient descent\n",
    "        #batch_size = 1\n",
    "        sparse_sgd_ts =[]\n",
    "        dense_sgd_ts = []\n",
    "\n",
    "        for size in [1,10,100]:\n",
    "            # sparse matrix case\n",
    "            t0 = time.time() \n",
    "            for j in range(5):\n",
    "                x = norm_d.rvs(size=n)\n",
    "                for i in range(num_of_tests):\n",
    "                    idx = batch_indices[i*size:(i+1)*size]\n",
    "                    logreg_grad(x, [A[idx], y[idx], 0, True])\n",
    "            sparse_sgd_ts.append(time.time() - t0)\n",
    "\n",
    "            # dense matrix case\n",
    "            t0 = time.time() \n",
    "            for j in range(5):\n",
    "                x = norm_d.rvs(size=n)\n",
    "                for i in range(num_of_tests):\n",
    "                    idx = batch_indices[i*size:(i+1)*size]\n",
    "                    logreg_grad(x, [denseA[idx], y[idx], 0, False])\n",
    "            dense_sgd_ts.append(time.time() - t0)\n",
    "        \n",
    "        new_df = pd.DataFrame({'Dataset':dataset_name,'M':m,'N':n,'L':L, 'Worst_L':worst_L,\n",
    "            'Sparse GD Time':sparse_gd_t,'Dense GD Time':dense_gd_t,\n",
    "            'Sparse SGD Time (batch 1)':sparse_sgd_ts[0],'Dense SGD Time (batch 1)':dense_sgd_ts[0],\n",
    "            'Sparse SGD Time (batch 10)':sparse_sgd_ts[1],'Dense SGD Time (batch 10)':dense_sgd_ts[1],\n",
    "            'Sparse SGD Time (batch 100)':sparse_sgd_ts[2],'Dense SGD Time (batch 100)':dense_sgd_ts[2]}, index=[0])\n",
    "        \n",
    "        df = pd.concat([df, new_df], axis=0, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_log_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>L</th>\n",
       "      <th>Worst_L</th>\n",
       "      <th>Sparse GD Time</th>\n",
       "      <th>Dense GD Time</th>\n",
       "      <th>Sparse SGD Time (batch 1)</th>\n",
       "      <th>Dense SGD Time (batch 1)</th>\n",
       "      <th>Sparse SGD Time (batch 10)</th>\n",
       "      <th>Dense SGD Time (batch 10)</th>\n",
       "      <th>Sparse SGD Time (batch 100)</th>\n",
       "      <th>Dense SGD Time (batch 100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a9a</td>\n",
       "      <td>32561</td>\n",
       "      <td>123</td>\n",
       "      <td>1.571920e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>1.280676</td>\n",
       "      <td>2.422997</td>\n",
       "      <td>0.125858</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.109341</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.120176</td>\n",
       "      <td>0.135580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a5a</td>\n",
       "      <td>6414</td>\n",
       "      <td>122</td>\n",
       "      <td>1.574027e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>0.219804</td>\n",
       "      <td>0.460540</td>\n",
       "      <td>0.131232</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.109513</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.111736</td>\n",
       "      <td>0.134254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian</td>\n",
       "      <td>690</td>\n",
       "      <td>14</td>\n",
       "      <td>7.036285e+06</td>\n",
       "      <td>2.500101e+09</td>\n",
       "      <td>0.074057</td>\n",
       "      <td>0.151252</td>\n",
       "      <td>0.127580</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.110364</td>\n",
       "      <td>0.007944</td>\n",
       "      <td>0.114059</td>\n",
       "      <td>0.008826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>768</td>\n",
       "      <td>8</td>\n",
       "      <td>8.606923e+03</td>\n",
       "      <td>1.899885e+05</td>\n",
       "      <td>0.069026</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.124771</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.108560</td>\n",
       "      <td>0.008137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart</td>\n",
       "      <td>270</td>\n",
       "      <td>13</td>\n",
       "      <td>2.671068e+04</td>\n",
       "      <td>9.036964e+04</td>\n",
       "      <td>0.063544</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>0.107990</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.111182</td>\n",
       "      <td>0.008264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset      M    N             L       Worst_L  Sparse GD Time  \\\n",
       "0         a9a  32561  123  1.571920e+00  3.500000e+00        1.280676   \n",
       "1         a5a   6414  122  1.574027e+00  3.500000e+00        0.219804   \n",
       "2  australian    690   14  7.036285e+06  2.500101e+09        0.074057   \n",
       "3    diabetes    768    8  8.606923e+03  1.899885e+05        0.069026   \n",
       "4       heart    270   13  2.671068e+04  9.036964e+04        0.063544   \n",
       "\n",
       "   Dense GD Time  Sparse SGD Time (batch 1)  Dense SGD Time (batch 1)  \\\n",
       "0       2.422997                   0.125858                  0.007039   \n",
       "1       0.460540                   0.131232                  0.006256   \n",
       "2       0.151252                   0.127580                  0.006469   \n",
       "3       0.010555                   0.113088                  0.007552   \n",
       "4       0.007892                   0.107990                  0.007228   \n",
       "\n",
       "   Sparse SGD Time (batch 10)  Dense SGD Time (batch 10)  \\\n",
       "0                    0.109341                   0.008079   \n",
       "1                    0.109513                   0.007683   \n",
       "2                    0.110364                   0.007944   \n",
       "3                    0.124771                   0.006399   \n",
       "4                    0.118056                   0.006960   \n",
       "\n",
       "   Sparse SGD Time (batch 100)  Dense SGD Time (batch 100)  \n",
       "0                     0.120176                    0.135580  \n",
       "1                     0.111736                    0.134254  \n",
       "2                     0.114059                    0.008826  \n",
       "3                     0.108560                    0.008137  \n",
       "4                     0.111182                    0.008264  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом dense в отличии sparse занял меньше времени на расчеты, кроме первых двух датасетов для GD. Это происходит из-за размерности датасета, т.к. для Dense матрицы требуется меньше памяти для хранения, но нужно проводить больше манипуляций для расчетов.\n",
    "Число функций m и L-гладкость влияют на время сходимости таким образом, что с увеличением m и L сходимость становится медленнее.\n",
    "Размер бача должен адаптироваться под задачу, не удается выявить определенные зависимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируйте здесь результаты своих экспериментов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Прокс-оператор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имплементируйте функцию, вычисляющую $\\text{prox}_R(x)$, где $R(x) = \\lambda \\|x\\|_1$, $\\lambda \\geq 0$. Ваша функция должна брать первым аргументом точку $x$, в которой нужно посчитать прокс, а вторым аргументом -- число $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#напишите код в этой ячейке\n",
    "def prox_R(x, lamb):\n",
    "    return np.maximum(np.abs(x) - lamb, 0) * np.sign(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для контроля корректности вызовите фунцию $\\texttt{prox}\\_\\texttt{test}$ из файла $\\texttt{tests.py}$. Если какой-то из тестов будет не пройден, то функция вернёт массив $[x, \\lambda, \\text{prox}_{R}(x)]$, где $x$ и $\\lambda$ - параметры, на которых Ваша фукция выдала неправильный ответ, $\\text{prox}_{R}(x)$ - это правильный ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все тесты пройдены успешно!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prox_test(prox_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3. SVRG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя заготовку, которая оставлена в файле $\\texttt{algorithms.py}$, имплементируйте $\\texttt{prox-SVRG}$ с мини-батчингом. Обратите внимание, что в методе можно передавать выборку индексов $\\texttt{indices}$ для контроля корректности работы. Однако если передавать $\\texttt{None}$ в качестве $\\texttt{indices}$, то в методе новые индексы тоже будут сэмплироваться не на каждй итерации. Сделано это осознанно: можн гораздо быстрее насэмплировать i.i.d. выборку размера, скажем, $N$ за один вызов функции, чем сэмплировать $N$ раз подряд выборку размера $1$. Это можно наглядно проверить. Для начала загрузим датасет $\\texttt{a9a}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число функций в сумме:  32561 , размерность задачи:  123\n",
      "Константа гладкости всей функции:  1.5719196992226612\n",
      "Средняя константа гладкости     :  3.467276803535652\n",
      "Худшая константа гладкости      :  3.5\n",
      "Доля ненулевых элементов:  0.11275696922074716\n",
      "CPU times: user 263 ms, sys: 11.5 ms, total: 274 ms\n",
      "Wall time: 269 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = \"a9a\"\n",
    "A, y, m, n, sparsity_A = prepare_data(dataset)\n",
    "print(\"Число функций в сумме: \", m, \", размерность задачи: \", n)\n",
    "L, average_L, worst_L = compute_L(dataset, A) #L может зависеть от запуска, поэтому для каждой задачи нужно сохранить свою константу L\n",
    "print(\"Константа гладкости всей функции: \", L)\n",
    "print(\"Средняя константа гладкости     : \", average_L)\n",
    "print(\"Худшая константа гладкости      : \", worst_L)\n",
    "print(\"Доля ненулевых элементов: \", sparsity_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нём 32561 функция в сумме. Предположим, что мы запускаем $\\texttt{prox-SGD}$ с размером батча $r = 1$ на $1000000$ итераций, что примерно 30 проходов по датасету, то есть не так уж и много. Давайте просэмплируем выборку размера $1000000$ за один раз и $1000000$ раз просэмплируем выборку размера $1$. Сначала просэмплируем сразу большую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 ms, sys: 0 ns, total: 10.4 ms\n",
      "Wall time: 7.51 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13101, 17104,  7187, ...,   805, 20263, 17914])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "randint.rvs(low=0, high=m, size=1000000, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На это ушло 1-3 секунды (зависит от мощности компьютера). А теперь рассмотрим второй вариант. Запустите следущую ячейку, а затем можете сходить заварить себе чай..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 0 ns, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1000000):\n",
    "    randint.rvs(low=0, high=m, size=1, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, выгоднее сэмплировать сразу много индексов, чтобы не терять много времени на сэмплирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки корректности работы метода предлагается воспользоваться заранее сгенерированной выборкой индексов и запустить для неё $\\texttt{prox-SVRG}$ со следующими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dump/test_indices_a9a.txt\", 'rb') as file:\n",
    "    test_indices = pickle.load(file)\n",
    "\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 3\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = True\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 338 ms, sys: 0 ns, total: 338 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = svrg(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, M=M, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=test_indices, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Некорректное сохранённое значение в массиве значений на позиции  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svrg_test(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства тестирования и построения графиков методов Вам предлагается использовать следующие функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная функция нужна для того, чтобы получить доступ к результатам работы метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results_from_file(filename, method, args):\n",
    "    if method == 'SVRG':\n",
    "        with open('dump/'+filename+'_SVRG_gamma_'+str(args[0])+\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])+\"_num_of_epochs_\"\n",
    "                  +str(args[3])\n",
    "              +\"_epoch_length_\"+str(args[4])+\"_batch_size_\"+str(args[5])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"SGD_const_stepsize\":\n",
    "        with open('dump/'+filename+'_SGD_const_stepsize_gamma_'+str(args[0])+\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])\n",
    "                  +\"_num_of_epochs_\"+str(args[3])+\"_batch_size_\"+str(args[4])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"SGD_decr_stepsize\":\n",
    "        with open('dump/'+filename+'_SGD_decr_stepsize_gamma_'+str(args[0][0])+\"_decr_period_\"\n",
    "                  +str(args[0][1])+\"_decr_coeff_\"+str(args[0][2])\n",
    "                  +\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])\n",
    "                  +\"_num_of_epochs_\"+str(args[3])+\"_batch_size_\"+str(args[4])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"prox-GD\":\n",
    "        with open('dump/'+filename+'_prox-GD_gamma_'+str(args[0])+\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])\n",
    "                  +\"_num_of_epochs_\"+str(args[3])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"GD\":\n",
    "        with open('dump/'+filename+'_GD_gamma_'+str(args[0])+\"_l2_\"+str(args[1])+\"_l1_\"+str(args[2])\n",
    "                  +\"_num_of_epochs_\"+str(args[3])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    if method == \"FISTA\":\n",
    "        with open('dump/'+filename+'_FISTA'+\"_l2_\"+str(args[0])+\"_l1_\"+str(args[1])\n",
    "                  +\"_num_of_epochs_\"+str(args[2])+\".txt\", 'rb') as file:\n",
    "            return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция нужна, чтобы выгрузить решение задачи для данного датасета при заданных $l_2$ и $l_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_solution(dataset, l2, l1, x_star, f_star):\n",
    "    filename = \"dump/\"+dataset+\"_solution_l2_\"+str(l2)+\"_l1_\"+str(l1)+\".txt\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump([x_star, f_star], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция нужна, чтобы выгрузить решение задачи для данного датасета при заданных $l_2$ и $l_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_solution(dataset, l2, l1):\n",
    "    with open('dump/'+dataset+'_solution_l2_'+str(l2)+\"_l1_\"+str(l1)+\".txt\", 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь запустите $\\texttt{prox-SVRG}$ с теми же параметрами, но на бОльшее число эпох. Сохраните $x^*$ и $f(x^*)$. Параметр $\\texttt{indices}$ выставляйте равным $\\texttt{None}$. Параметры $l_2$ и $l_1$ выбирайте согласно PDF-документу с заданиями. Посчитайте количество ненулевых значений в найденном решении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "# задать параметры\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 500\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = False\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = svrg(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, M=M, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=None, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)\n",
    "print(\"Найденное значение: \", res['func_vals'][-1])\n",
    "print(\"Процент ненулевых координат в найденном решении: \", np.count_nonzero(res['last_iter'])/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код здесь\n",
    "# сохранить решение x_star и f_star\n",
    "save_solution(dataset, l2, l1, res['last_iter'], res['func_vals'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните найденное значение с тем, которое выдаёт стандартный солвер (сравните результаты для $l_1 = 0$ и $l_1 = \\frac{L}{1000}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param = [A, y, l2, True, l1]\n",
    "res_solver = minimize(F, x_init, args = param, jac=logreg_grad_plus_lasso, \n",
    "                      options={'maxiter':5000, 'disp':True}, tol=1e-10)\n",
    "\n",
    "print(res_solver.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь повторите эксперимент с $S = 3$, но передайте туда найденные при помощи $\\texttt{prox-SVRG}$ $x^*$ и $f(x^*)$ в качестве $\\texttt{x}{\\_}\\texttt{star}$ и $\\texttt{f}{\\_}\\texttt{star}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "x_star = read_solution(dataset, l2, l1)[0]\n",
    "f_star = read_solution(dataset, l2, l1)[1]\n",
    "S = 3\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = False\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = svrg(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, M=M, max_t=np.inf,\n",
    "     batch_size=batch_size, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая функция позволяет строить графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(args):\n",
    "    supported_modes_y = ['squared_distances', 'func_vals']\n",
    "    supported_modes_x = ['time', 'data_passes', 'iters']\n",
    "    \n",
    "    dataset = args[0]\n",
    "    filename = args[1]\n",
    "    mode_y = args[2]\n",
    "    mode_x = args[3]\n",
    "    figsize = args[4]\n",
    "    fontsize = args[5]\n",
    "    title = args[6]\n",
    "    methods = args[7]\n",
    "    \n",
    "    assert(mode_y in supported_modes_y)\n",
    "    assert(mode_x in supported_modes_x)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(title, fontsize=fontsize)\n",
    "    marker = itertools.cycle(('+', 'd', 'x', 'o', '^', 's', '*', 'p', '<', '>', '^'))\n",
    "    \n",
    "    num_of_methods = len(methods)\n",
    "    for idx, method in enumerate(methods):\n",
    "        res = read_results_from_file(filename, method[0], method[1])\n",
    "        if method[3] == None:\n",
    "            length = len(res['iters'])\n",
    "        else:\n",
    "            length = method[3]\n",
    "        plt.semilogy(res[mode_x][0:length], res[mode_y][0:length] / res[mode_y][0], linewidth=2, marker=next(marker), \n",
    "            markersize = 20, \n",
    "            markevery=range(-idx*int(length/(10*num_of_methods)), len(res[mode_x][0:length]), int(length/10)), \n",
    "            label = method[0]+method[2])\n",
    "        \n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(2,1), loc=\"upper right\", fontsize=fontsize)\n",
    "    if mode_x == 'time':\n",
    "        plt.xlabel(r\"Time, $s$\", fontsize=fontsize)\n",
    "    if mode_x == 'sampled_grads':\n",
    "        plt.xlabel(r\"Number of sampled gradients / number of data samples\", fontsize=fontsize)\n",
    "    if mode_x == 'iters':\n",
    "        plt.xlabel(r\"Number of iterations\", fontsize=fontsize)\n",
    "    if mode_y == 'squared_distances':\n",
    "        plt.ylabel(r\"$\\frac{||x^k - x^*||_2^2}{||x^0 - x^*||_2^2}$\", fontsize=fontsize)\n",
    "    if mode_y == 'func_vals':\n",
    "        plt.ylabel(r\"$\\frac{f(x^k)-f(x^())}{f(x^0)-f(x^*)}$\", fontsize=fontsize)\n",
    "    \n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    _ = plt.yticks(fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"a9a\"\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "\n",
    "#это массив с методами и их парамтерами, для которых мы хотим построить графики\n",
    "#в кждом массиве внутри этого массива есть 4 элемента\n",
    "#первый элемент -- название метода\n",
    "#второй элемент -- [параметры, чтобы открыть файл]\n",
    "#третий элемент -- метка, которая будет использоваться в легенде графика (чтобы понимать, чему отвечает та или иная траектория)\n",
    "#четвёртый элемент -- None или целое число, если Вы хотите обрезать график справа\n",
    "methods = [\n",
    "         ['SVRG', [gamma, l2, l1, 3, int(2*m/10), 10], \n",
    "           ' третий аргумент', None],\n",
    "]\n",
    "mode_y = 'squared_distances'\n",
    "mode_x = 'time'\n",
    "figsize = (12, 8)\n",
    "fontsize = 20\n",
    "title = dataset+\", (m,n) = (\"+str(m)+\",\"+str(n)+\"), l2 = L/\"+str(int(L/l2))+\", l1 = L/\"+str(int(L/l1))\n",
    "\n",
    "args_for_plots = [dataset, filename, mode_y, mode_x, figsize, fontsize, title, methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(args=args_for_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте разные размеры батчей и разные $l_2$ и $l_1$, как это указано в задании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4. SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имплементируйте $\\texttt{prox-SGD}$ с мини-батчингом и постоянным шагом. Имплементируйте $\\texttt{prox-SGD}$ с мини-батчингом и периодически уменьшающимся шагом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dump/test_indices_a9a.txt\", 'rb') as file:\n",
    "    test_indices = pickle.load(file)\n",
    "\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 3\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = True\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = sgd_const_stepsize(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=test_indices, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_const_test(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dump/test_indices_a9a.txt\", 'rb') as file:\n",
    "    test_indices = pickle.load(file)\n",
    "\n",
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "batch_size = 10\n",
    "M = int(2*m/batch_size)\n",
    "gamma = 1.0/(6*(L+l2))\n",
    "gamma_schedule = [gamma, 1, 0.5]\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 10\n",
    "save_info_period = 100\n",
    "\n",
    "#эти 2 параметра выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse_full = True\n",
    "sparse_stoch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = sgd_decr_stepsize(filename=filename, x_init=x_init, A=A, y=y, gamma_schedule=gamma_schedule, l2=l2, \n",
    "     sparse_full=sparse_full, sparse_stoch=sparse_stoch, \n",
    "     l1=l1, S=S, max_t=np.inf,\n",
    "     batch_size=batch_size, indices=test_indices, save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_decr_test(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если тесты пройдены успешно, то выполните эксперименты, описанные в задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5. prox-GD, FISTA и GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имплементируйте $\\texttt{prox-GD}$, $\\texttt{FISTA}$ и $\\texttt{GD}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "gamma = 1.0/((L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 1000\n",
    "save_info_period = 10\n",
    "\n",
    "#этото параметр выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = prox_gd(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse=sparse, l1=l1, S=S, max_t=np.inf,\n",
    "     save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_gd_test(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 1000\n",
    "save_info_period = 10\n",
    "\n",
    "#этот параметр выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = FISTA(filename=filename, x_init=x_init, A=A, y=y, L=L+l2, mu=l2, \n",
    "     sparse=sparse, l1=l1, S=S, max_t=np.inf,\n",
    "     save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_test(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=dataset+\"_x_init_all_ones\"\n",
    "x_init = np.ones(n)\n",
    "l2 = L / 10000\n",
    "l1 = L / 1000\n",
    "gamma = 1.0/((L+l2))\n",
    "x_star = None\n",
    "f_star = None\n",
    "S = 1000\n",
    "save_info_period = 10\n",
    "\n",
    "#этото параметр выставите в соответствии с вашими экспериментами по разреженности матрицы\n",
    "sparse = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = gd(filename=filename, x_init=x_init, A=A, y=y, gamma=gamma, l2=l2, \n",
    "     sparse=sparse, l1=l1, S=S, max_t=np.inf,\n",
    "     save_info_period=save_info_period, \n",
    "     x_star=x_star, f_star=f_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите функцию, тестирующую корректность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_test(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если тесты пройдены успешно, то выполните эксперименты, описанные в задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6. Сравнение методов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 7. Эксперименты с другим датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ce8a0452749bc4b5f03b6e5df3595212fc7910e9903d106d143563d7de8650a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
